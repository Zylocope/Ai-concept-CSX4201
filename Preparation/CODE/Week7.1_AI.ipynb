{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Loss: [0.06961777]\n",
      "Epoch 1000, Average Loss: [0.00885499]\n",
      "Epoch 2000, Average Loss: [0.0040677]\n",
      "Epoch 3000, Average Loss: [0.00256532]\n",
      "Epoch 4000, Average Loss: [0.00185353]\n",
      "Epoch 5000, Average Loss: [0.00144339]\n",
      "Epoch 6000, Average Loss: [0.00117835]\n",
      "Epoch 7000, Average Loss: [0.00099367]\n",
      "Epoch 8000, Average Loss: [0.00085793]\n",
      "Epoch 9000, Average Loss: [0.00075414]\n",
      "Final weights: [6.18145689 6.18155127]\n",
      "Final bias: [-2.84461123]\n",
      "Input: [0 0], Predicted Output: 0.0550, Actual Target: 0\n",
      "Input: [0 1], Predicted Output: 0.9657, Actual Target: 1\n",
      "Input: [1 0], Predicted Output: 0.9657, Actual Target: 1\n",
      "Input: [1 1], Predicted Output: 0.9999, Actual Target: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    " \n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    " \n",
    "# Initializing weights and bias\n",
    "np.random.seed(42)  # for reproducibility\n",
    "weights = np.random.rand(2)  # weights for two inputs\n",
    "bias = np.random.rand(1)  # one bias\n",
    " \n",
    "# Dataset\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "targets = np.array([0, 1, 1, 1])  # Adjusted to correct OR problem representation\n",
    " \n",
    "# Learning rate\n",
    "learning_rate = 0.1  # Increased for faster convergence\n",
    " \n",
    "# Training loop\n",
    "for epoch in range(10000):  # Reduced number of epochs\n",
    "    total_error = 0\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    " \n",
    "    for i in indices:\n",
    "        input_layer = inputs[i]\n",
    "        target = targets[i]\n",
    " \n",
    "        z = np.dot(input_layer, weights) + bias\n",
    "        output = sigmoid(z)\n",
    "        error = 0.5 * (target - output) ** 2\n",
    "        total_error += error\n",
    " \n",
    "        dE_dy = output - target\n",
    "        dy_dz = sigmoid_derivative(z)\n",
    "        dz_dw = input_layer\n",
    "        dz_db = 1\n",
    " \n",
    "        gradient_weights = dE_dy * dy_dz * dz_dw\n",
    "        gradient_bias = dE_dy * dy_dz * dz_db\n",
    " \n",
    "        weights -= learning_rate * gradient_weights\n",
    "        bias -= learning_rate * gradient_bias\n",
    " \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Average Loss: {total_error / len(inputs)}\")\n",
    " \n",
    "print(\"Final weights:\", weights)\n",
    "print(\"Final bias:\", bias)\n",
    " \n",
    "for i in range(len(inputs)):\n",
    "    z = np.dot(inputs[i], weights) + bias\n",
    "    output = sigmoid(z)\n",
    "    print(f\"Input: {inputs[i]}, Predicted Output: {output[0]:.4f}, Actual Target: {targets[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is neural network?\n",
    "A neural network is a computational model inspired by the way biological neural networks in the human brain process information. It consists of interconnected nodes, or neurons, organized in layers. Here are the key components:\n",
    "\n",
    "Neurons (Nodes): Basic units that receive input, process it, and pass the output to the next layer.\n",
    "Layers:\n",
    "Input Layer: Receives the initial data.\n",
    "Hidden Layers: Intermediate layers that process inputs from the input layer.\n",
    "Output Layer: Produces the final output.\n",
    "Weights: Parameters that determine the strength of the connection between neurons.\n",
    "Biases: Additional parameters that adjust the output along with the weighted sum of inputs.\n",
    "Activation Functions: Functions applied to the input of a neuron to introduce non-linearity (e.g., sigmoid, ReLU).\n",
    "Neural networks are used for various tasks such as classification, regression, and pattern recognition. They are the foundation of deep learning, where networks with many layers (deep neural networks) are used to model complex patterns in data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
